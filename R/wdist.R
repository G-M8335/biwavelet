#' Compute dissimilarity between two wavelet spectra
#' @author Tarik C. Gouhier (tarik.gouhier@@gmail.com)
#' 
#' @param wt1 \code{power}, \code{wave} or \code{rsq} matrix from
#'   \code{biwavelet} object generated by \code{wt}, \code{xwt}, or \code{wtc}.
#' @param wt2 \code{power}, \code{wave} or \code{rsq} matrix from
#'   \code{biwavelet} object generated by \code{wt}, \code{xwt}, or \code{wtc}.
#' @param cutoff cutoff value used to compute dissimilarity. Only orthogonal
#'   axes that contribute more than \code{1-cutoff} to the total covariance
#'   between the two wavelet spectra will be used to compute their
#'   dissimilarity. Default is \code{0.99}.
#'   
#' @return Returns wavelet dissimilarity.
#' 
#' @references
#' Rouyer, T., J. M. Fromentin, F. Menard, B. Cazelles, K. Briand, R. Pianet, 
#' B. Planque, and N. C. Stenseth. 2008. Complex interplays among population
#' dynamics, environmental forcing, and exploitation in fisheries.
#' \emph{Proceedings of the National Academy of Sciences} 105:5420-5425.
#' 
#' Rouyer, T., J. M. Fromentin, N. C. Stenseth, and B. Cazelles. 2008.
#' Analysing multiple time series and extending significance testing in
#' wavelet analysis. \emph{Marine Ecology Progress Series} 359:11-23.
#' 
#' @examples
#' t1 <- cbind(1:100, sin(seq(from = 0, to = 10*2*pi, length.out = 100)))
#' t2 <- cbind(1:100, sin(seq(from = 0, to = 10*2*pi, length.out = 100)+0.1*pi))
#' ## Compute wavelet spectra
#' wt.t1 <- wt(t1)
#' wt.t2 <- wt(t2)
#' ## Compute dissimilarity
#' wdist(wt.t1$wave, wt.t2$wave)
#' 
wdist <- function (wt1, wt2, cutoff=0.99) {
  wcov <- Re(wt1) %*% (t(Re(wt2)))
  wsvd <- svd(wcov)
  
  ## Cutoff point: find first value greater than cutoff (select min of 3 freqs)
  nfreqs <- max(3, which(cumsum(sqrt(wsvd$d))/sum(sqrt(wsvd$d)) >= cutoff)[1])
  u <- wsvd$u[1:nfreqs,]
  v <- wsvd$v[1:nfreqs,]
  
  Lnk <- t(u[, 1:nfreqs]) %*% Re(wt1[1:nfreqs,])
  Ljk <- t(v[, 1:nfreqs]) %*% Re(wt2[1:nfreqs,])
  
  ## Distances 1
  D1 <- rowSums(atan(abs(
    (Lnk[,1:(NCOL(Lnk)-1)] - Ljk[,1:(NCOL(Ljk)-1)]) -
      (Lnk[,2:NCOL(Lnk)] - Ljk[,2:NCOL(Ljk)]))))
  
  ## Distances 2
  D2 <- rowSums(atan(abs(
    (u[,1:(NROW(u)-1)] - v[,1:(NROW(v)-1)]) -
      (u[,2:NROW(u)] - v[,2:NROW(v)]))))
  
  ## Weights based on the amount of variance explained by each axis
  w <- sqrt(wsvd$d[1:nfreqs]) / sum(sqrt(wsvd$d[1:nfreqs]))
  D <- weighted.mean(D1+D2, w)
  return (D)
}
